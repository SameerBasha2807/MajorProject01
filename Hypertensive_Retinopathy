import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms as T
from torch.utils.data import Dataset, DataLoader, random_split
from PIL import Image
import pandas as pd
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import random
import matplotlib.pyplot as plt

torch.manual_seed(2025)

class CustomDataset(Dataset):
    def __init__(self, root, transformations=None):
        self.transformations = transformations
        meta_data = pd.read_csv(f"{root}/2-Groundtruths/HRDC Hypertensive Classification Training Labels.csv")
        im_names = list(meta_data["Image"])
        gt_names = list(meta_data["Hypertensive"])
        self.meta_data = {}
        self.cls_names, self.cls_counts, count = {}, {}, 0
        for idx, im_path in enumerate(im_names):
            class_name = gt_names[idx]
            if class_name not in self.cls_names:
                self.cls_names[class_name] = count
                self.cls_counts[class_name] = 1
                count += 1
            else:
                self.cls_counts[class_name] += 1
            self.meta_data[f"{root}/1-Images/1-Training Set/{im_path}"] = self.cls_names[class_name]

    def __len__(self):
        return len(self.meta_data)

    def __getitem__(self, idx):
        im_path = list(self.meta_data.keys())[idx]
        im = Image.open(im_path).convert("RGB")
        gt = self.meta_data[im_path]
        if self.transformations:
            im = self.transformations(im)
        return im, gt

def get_dls(root, transformations, bs, split=[0.9,0.05,0.05], ns=4):
    ds = CustomDataset(root=root, transformations=transformations)
    total_len = len(ds)
    tr_len = int(total_len*split[0])
    vl_len = int(total_len*split[1])
    ts_len = total_len - (tr_len+vl_len)
    tr_ds, vl_ds, ts_ds = random_split(ds, [tr_len, vl_len, ts_len])
    tr_dl = DataLoader(tr_ds, batch_size=bs, shuffle=True, num_workers=ns)
    val_dl = DataLoader(vl_ds, batch_size=bs, shuffle=False, num_workers=ns)
    ts_dl = DataLoader(ts_ds, batch_size=1, shuffle=False, num_workers=ns)
    return tr_dl, val_dl, ts_dl, ds.cls_names

mean, std, im_size = [0.485,0.456,0.406], [0.229,0.224,0.225], 224
tfs = T.Compose([
    T.RandomResizedCrop(im_size, scale=(0.7,1.0)),
    T.RandomHorizontalFlip(),
    T.RandomRotation(30),
    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),
    T.ToTensor(),
    T.Normalize(mean,std),
    T.RandomErasing(p=0.2)
])

root = "/kaggle/input/hypertension-and-hypertensive-retinopathy-dataset/1-Hypertensive Classification/1-Hypertensive Classification"
tr_dl, val_dl, ts_dl, classes = get_dls(root=root, transformations=tfs, bs=16)

class LabelSmoothingCrossEntropy(nn.Module):
    def __init__(self, eps=0.1):
        super().__init__()
        self.eps = eps
        self.log_softmax = nn.LogSoftmax(dim=-1)
    def forward(self, pred, target):
        n = pred.size(-1)
        log_preds = self.log_softmax(pred)
        loss = -log_preds.gather(dim=-1, index=target.unsqueeze(1)).squeeze(1)
        loss = loss * (1 - self.eps) + self.eps / n
        return loss.mean()

class CNN_Transformer_Patch(nn.Module):
    def __init__(self, num_classes, cnn_out=2048, patch_size=2, emb_dim=512, nhead=8, num_layers=3):
        super().__init__()
        resnet = models.resnet50(pretrained=True)
        self.cnn = nn.Sequential(*list(resnet.children())[:-2])  
        self.avgpool = nn.AdaptiveAvgPool2d((28,28))

        self.patch_size = patch_size
        self.emb_dim = emb_dim
        self.n_patches = (28 // patch_size)**2

        self.proj = nn.Linear(cnn_out*patch_size*patch_size, emb_dim)
        self.pos_embed = nn.Parameter(torch.randn(1, self.n_patches, emb_dim))

        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=nhead, dim_feedforward=1024, dropout=0.1)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        self.classifier = nn.Linear(emb_dim, num_classes)

    def forward(self, x):
        batch = x.size(0)
        feat = self.cnn(x)
        feat = self.avgpool(feat)  

        patches = feat.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)
        patches = patches.contiguous().view(batch, feat.size(1), -1, self.patch_size, self.patch_size)
        patches = patches.permute(0,2,1,3,4).contiguous().view(batch, self.n_patches, -1)  

        x = self.proj(patches) + self.pos_embed
        x = self.transformer(x)
        x = x.mean(dim=1)
        x = self.classifier(x)
        return x

device = "cuda" if torch.cuda.is_available() else "cpu"
m = CNN_Transformer_Patch(num_classes=len(classes)).to(device)

class_counts = np.array(list(classes.values()))
class_counts[class_counts==0]=1
weights = 1./class_counts
weights = torch.tensor(weights, dtype=torch.float).to(device)

criterion = LabelSmoothingCrossEntropy(eps=0.1)
optimizer = optim.Adam(m.parameters(), lr=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)

scaler = torch.cuda.amp.GradScaler()
epochs = 20
train_losses, val_losses = [], []

for epoch in range(epochs):
    m.train()
    running_loss = 0
    for imgs, labels in tr_dl:
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        with torch.cuda.amp.autocast():
            outputs = m(imgs)
            loss = criterion(outputs, labels)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        running_loss += loss.item()
    train_losses.append(running_loss/len(tr_dl))

    m.eval()
    val_loss, correct, total = 0, 0, 0
    with torch.no_grad():
        for imgs, labels in val_dl:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = m(imgs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs,1)
            correct += (preds==labels).sum().item()
            total += labels.size(0)
    val_losses.append(val_loss/len(val_dl))
    acc = 100*correct/total
    print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {acc:.2f}%")
    scheduler.step()

plt.plot(train_losses,label="Train Loss")
plt.plot(val_losses,label="Val Loss")
plt.legend()
plt.show()

m.eval()
all_labels, all_preds = [], []
with torch.no_grad():
    for imgs, labels in ts_dl:
        imgs, labels = imgs.to(device), labels.to(device)
        outputs = m(imgs)
        _, preds = torch.max(outputs,1)
        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(preds.cpu().numpy())

test_acc = 100*np.sum(np.array(all_labels)==np.array(all_preds))/len(all_labels)
print(f"\nFinal Test Accuracy: {test_acc:.2f}%")

target_names = [str(k) for k in classes.keys()]
print("\nClassification Report:")
print(classification_report(all_labels, all_preds, target_names=target_names))

print("\nConfusion Matrix:\n")
print(confusion_matrix(all_labels, all_preds))

print("\nSample Predictions (Actual vs Predicted):")
idxs = random.sample(range(len(all_labels)), min(10, len(all_labels)))
inv_classes = {v:k for k,v in classes.items()}
for i in idxs:
    print(f"Actual: {inv_classes[all_labels[i]]}, Predicted: {inv_classes[all_preds[i]]}")

print(f"\nModel used: CNN + Transformer Patch Model")
print(f"Final Test Accuracy: {test_acc:.2f}%")


model_path = "cnn_transformer_hypertension.pth"
torch.save(m.state_dict(), model_path)
print(f"Model saved as {model_path}")
import shutil
shutil.copy(model_path, "/kaggle/working/")
print(f"Model copied to /kaggle/working/ folder. Download it from the output directory.")
