import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import glob
import matplotlib.pyplot as plt
import seaborn as sns

DATA_DIR = "/kaggle/input/glaucoma-dataset/ACRIMA"
PARTITIONED_DIR = os.path.join(DATA_DIR, "PARTITIONED")
TRAIN_DIR = os.path.join(PARTITIONED_DIR, "Training")
TEST_DIR = os.path.join(PARTITIONED_DIR, "Testing")

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

BATCH_SIZE = 20
LEARNING_RATE = 1e-4
NUM_EPOCHS = 20
IMAGE_SIZE = 224

class GlaucomaDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = ["glaucoma", "normal"]
        self.image_paths = []
        self.labels = []

        image_extensions = (".jpg", ".jpeg", ".png", ".bmp", ".gif")

        for class_name in self.classes:
            class_path = os.path.join(self.root_dir, class_name)
            for img_path in glob.glob(os.path.join(class_path, "*")):
                if img_path.lower().endswith(image_extensions):
                    self.image_paths.append(img_path)
                    self.labels.append(self.classes.index(class_name))
        
        if not self.image_paths:
            print(f"Warning: No images found in {root_dir} with extensions {image_extensions}.")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert("RGB")
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, label

data_transforms = {
    "train": transforms.Compose([
        transforms.Resize(IMAGE_SIZE),
        transforms.CenterCrop(IMAGE_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]),
    "val": transforms.Compose([
        transforms.Resize(IMAGE_SIZE),
        transforms.CenterCrop(IMAGE_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
}

def get_model():
    model = models.vit_b_16(pretrained=True)
    
    for param in model.parameters():
        param.requires_grad = False

    in_features = model.heads.head.in_features
    model.heads.head = nn.Linear(in_features, 2)
    
    print("Using Vision Transformer (ViT) model: ViT-B/16")
    
    return model

def train_model(model, train_loader, criterion, optimizer, num_epochs):
    model.train()
    print("Starting training...")
    for epoch in range(num_epochs):
        running_loss = 0.0
        for i, (images, labels) in enumerate(train_loader):
            images = images.to(DEVICE)
            labels = labels.to(DEVICE)

            outputs = model(images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * images.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")
    print("Training finished.")

def evaluate_model(model, test_loader):
    model.eval()
    print("Evaluating model...")
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(DEVICE)
            labels = labels.to(DEVICE)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='binary')
    recall = recall_score(all_labels, all_preds, average='binary')
    f1 = f1_score(all_labels, all_preds, average='binary')

    print(f"Test Accuracy: {accuracy:.4f}")
    print(f"Test Precision: {precision:.4f}")
    print(f"Test Recall: {recall:.4f}")
    print(f"Test F1-Score: {f1:.4f}")
    
    return all_labels, all_preds

if __name__ == "__main__":
    train_dataset = GlaucomaDataset(root_dir=TRAIN_DIR, transform=data_transforms["train"])
    test_dataset = GlaucomaDataset(root_dir=TEST_DIR, transform=data_transforms["val"])

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

    model = get_model().to(DEVICE)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

    train_model(model, train_loader, criterion, optimizer, NUM_EPOCHS)

    true_labels, predicted_labels = evaluate_model(model, test_loader)

    print("\n--- Model Analysis ---")

    cm = confusion_matrix(true_labels, predicted_labels)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Glaucoma', 'Normal'], yticklabels=['Glaucoma', 'Normal'])
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

    print("\nSample of Actual vs. Predicted Labels:")
    for i in range(10):
        actual_class = test_dataset.classes[true_labels[i]]
        predicted_class = test_dataset.classes[predicted_labels[i]]
        print(f"Sample {i+1}: Actual: {actual_class}, Predicted: {predicted_class}")

    model_filename = "glaucoma_vit_model.pth"
   
    torch.save(model.state_dict(), model_filename)
    print(f"\nModel saved to {model_filename}")




OUTPUT:
100%|██████████| 330M/330M [00:01<00:00, 189MB/s]
Using Vision Transformer (ViT) model: ViT-B/16
Starting training...
Epoch [1/20], Loss: 0.6565
Epoch [2/20], Loss: 0.5488
Epoch [3/20], Loss: 0.4689
Epoch [4/20], Loss: 0.4129
Epoch [5/20], Loss: 0.3713
Epoch [6/20], Loss: 0.3388
Epoch [7/20], Loss: 0.3137
Epoch [8/20], Loss: 0.2927
Epoch [9/20], Loss: 0.2760
Epoch [10/20], Loss: 0.2603
Epoch [11/20], Loss: 0.2476
Epoch [12/20], Loss: 0.2365
Epoch [13/20], Loss: 0.2274
Epoch [14/20], Loss: 0.2179
Epoch [15/20], Loss: 0.2103
Epoch [16/20], Loss: 0.2033
Epoch [17/20], Loss: 0.1968
Epoch [18/20], Loss: 0.1912
Epoch [19/20], Loss: 0.1857
Epoch [20/20], Loss: 0.1806
Training finished.
Evaluating model...
Test Accuracy: 0.9645
Test Precision: 0.9524
Test Recall: 0.9677
Test F1-Score: 0.9600

--- Model Analysis ---

Sample of Actual vs. Predicted Labels:
Sample 1: Actual: glaucoma, Predicted: glaucoma
Sample 2: Actual: glaucoma, Predicted: glaucoma
Sample 3: Actual: glaucoma, Predicted: glaucoma
Sample 4: Actual: glaucoma, Predicted: glaucoma
Sample 5: Actual: glaucoma, Predicted: glaucoma
Sample 6: Actual: glaucoma, Predicted: glaucoma
Sample 7: Actual: glaucoma, Predicted: glaucoma
Sample 8: Actual: glaucoma, Predicted: normal
Sample 9: Actual: glaucoma, Predicted: glaucoma
Sample 10: Actual: glaucoma, Predicted: glaucoma

Model saved to glaucoma_vit_model.pth
